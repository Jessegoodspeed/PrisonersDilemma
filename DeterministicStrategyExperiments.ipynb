{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2baea834-2933-459b-97c7-b20345fae3e3",
   "metadata": {},
   "source": [
    "## Tutorial: Using pd_exp to create experiments with Prisoner's Dilemma Tournaments\n",
    "This notebook walks through two different experimental setups to showcase the code functionality of the `pd_exp` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4f417-0d8c-4e20-8e3c-dd20db9f068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local modules to import\n",
    "from code import pd_exp\n",
    "from code.helper_funcs import partitions\n",
    "from code.settings import player_names, stag\n",
    "\n",
    "# Other Python modules used\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time, json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e1c40-0c33-434d-baff-7055e8ffd862",
   "metadata": {},
   "source": [
    "`pd_exp` was designed to collect data from multiple groups of round-robin tournaments. To keep vocabulary consistent, let me introduce some project terminology:\n",
    "- _Supergame_: a single PD instance between two players that consists of one or more rounds of play.\n",
    "- _Tournament_: a round-robin tournament between a select group of players. This concept can also be referred to as a team.\n",
    "- _System_: a collection of one or more teams.\n",
    "\n",
    "In the code below, I setup data collection for two different experiments. In experiment 1, we consider how measured outcomes differ within one team of deterministic players in two different game variations: classic PD and Stag Hunt. In experiment 2, we expand on experiment 1 to consider multiple different systems, where each system is comprised of two teams.\n",
    "\n",
    "#### __Team Metrics__\n",
    "To measure team outcomes, we use the following metrics: 1) minimum of normalized player scores, 2) average of normalized player scores, and 3) average normalized CC distribution.\n",
    "\n",
    "##### __The Minumum (Min Score) and Average (Avg Score) of Normalized Player Scores__\n",
    "The normalized score for a player, $j$, is computed as \n",
    "$$\n",
    "S_j = \\sum_{i\\neq j} \\frac{\\text{Score-per-turn against opponent } i}{\\text{Total opponents}} = \\frac{1}{\\text{Total opponents}} \\sum_{i\\neq j} \\frac{S_{ji}}{T_{ji}},\n",
    "$$\n",
    "where $S_{ji}$ is player $j$'s score against player $i$ and $T_{ji}$ is the total turns played between player $j$ and $i$.\n",
    "\n",
    "The minimum and average values across all normalized player scores are taken as aggregate group measures to reflect group welfare.\n",
    "\n",
    "##### __The Average Normalized CC Distribution (Avg CC Dist)__\n",
    "The normalized CC distribution for a player represents the proportion of turns where they and their opponent chose to cooperate (CC) out of the total turns given. The average across each player's normalized CC distribution is used as an aggregate measure for overall group cooperation. The average normalized CC distribution is computed as \n",
    "\n",
    "$$\n",
    "\\frac{1}{N} \\sum_{j=1}^N \\frac{1}{N-1} \\sum_{i \\neq j} \\frac{CC \\text{ count against player } i}{\\text{total turns against player }i}\n",
    "$$\n",
    "\n",
    "where $N$ is the total number of players in a model, $j$ is a given player, and $i$ is every other player.\n",
    "\n",
    "\n",
    "#### __System Metrics__\n",
    "To measure system outcomes, we extend the above metrics and use six different measures:\n",
    "1. System Minimum Score (SYS MIN)\n",
    "2. System Average Score (SYS AVG)\n",
    "3. Minimum of Team Average Scores (Min of Team Avgs)\n",
    "4. Average of Team Minimum Scores (Avg of Team Mins)\n",
    "5. System CC Distribution Average (SYS CC Dist AVG)\n",
    "6. System CC Distribution Average (SYS CC Dist MIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188db13-d785-4a58-aeef-37de211d4782",
   "metadata": {},
   "source": [
    "### Experiment 1: Comparing team performance across classic PD and Stag Hunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f0431-43b4-4eeb-80e8-cc21321e8739",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For experiment 1\n",
    "# Since this simulation gathers data for systems, I coded systems as ordered-lists of \n",
    "# teams. To implement ordered-lists of teams I nested player_names within closed-brackets and then a tuple to create an ordered-list.\n",
    "# The simulation code allows for processing numerous systems, so I enclose the tournament within another pair\n",
    "# of closed-brackets and then a tuple.\n",
    "\n",
    "part_list = tuple([tuple([player_names])]) # 'part' is shorthand for partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e30ca-b42a-40dc-a78f-0de29bd003b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(part_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf84be-99c9-4854-a170-6ebfb09dbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total count of systems: ',len(part_list))  #Should be 5775 for n=12 and k=4\n",
    "start_time = time.time()\n",
    "\n",
    "print('Instantiate PD Experiments with different game types')\n",
    "# To instantiate a PD Experiment, I use the PDExp constructor with at partition list and game-type, which is \n",
    "# by default the classic PD)\n",
    "classic_pdExp = pd_exp.PdExp(part_list)\n",
    "stag_pdExp = pd_exp.PdExp(part_list,game_type=stag)\n",
    "\n",
    "\n",
    "print('Running experiments and computing data')\n",
    "# To generate the simulation data and compute the group metrics, I use the run_experiments() method.\n",
    "classic_pdExp.run_experiments()\n",
    "stag_pdExp.run_experiments()\n",
    "\n",
    "\n",
    "print('Saving experiment data')\n",
    "### For experiment 1\n",
    "path = 'Data/Experiment1/'\n",
    "classic_pdExp.save_data(path, 'ClassicPD_test_DELETE')  # CHANGE file_name string when necessary\n",
    "stag_pdExp.save_data(path, 'StagHunt_test_DELETE')  # CHANGE file_name string when necessary\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd49588-00e9-4dd8-bf34-ea850b236210",
   "metadata": {},
   "source": [
    "### Experiment 1: Data Comparison Across Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b10f0-b437-44e1-83b6-4b1c2643fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve saved data\n",
    "classic_dataf1 = pd.read_csv('Data/Experiment1/ClassicPD_test_DELETE_RPST_3_1_0_5.csv', index_col=0)\n",
    "stagHunt_dataf1 = pd.read_csv('Data/Experiment1/StagHunt_test_DELETE_RPST_5_1_0_3.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcab3d-e26c-415c-88f1-3550e787db80",
   "metadata": {},
   "source": [
    "#### _The System ID_\n",
    "Since these experiments are with unique players, each system is denoted with a unique ID that is comprised of numbers, commas, and underscores. The numbers represent players and determined by the alphabetical order of the player's strategy out of the total set of player strategies in system. The commas delimit players of the same team, and underscores delimit different teams of the same system. Note the system IDs and team compositions below and how they differ between experiment 1 and experiment 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1a6a8-599c-46f6-88c2-42b9dcc17f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use option_context to customize the limits of the dataframe display\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(classic_dataf1[['System ID', 'Team1', 'Team1 Avg Score',\n",
    "       'Team1 Min Score', 'Team1 Avg CC Dist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c522f277-784b-4ddb-a185-c2894b80eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(stagHunt_dataf1[['System ID', 'Team1', 'Team1 Avg Score',\n",
    "       'Team1 Min Score', 'Team1 Avg CC Dist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b29d674-cb2d-436a-b81b-50ab3a6afc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIDENOTE: Documentation (i.e. docstring) for code can be retrieved with '?'. Here are some examples.\n",
    "\n",
    "?pd_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998d194-8729-46d8-99f4-d523b295fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd_exp.PdExp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbfc3c-5105-4768-9777-e9d859b9e0d6",
   "metadata": {},
   "source": [
    "### Experiment 2: Comparing systems of 3 teams across classic PD and Stag Hunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd46ae-199c-4257-b19a-d2b5c72861ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For experiment 2\n",
    "# To create numerous systems with a partitioned list of teams can take time, so I save the tuple of systems \n",
    "# to file immediately after computing all k-partition subsets of a set of players  to avoid having to recompute \n",
    "# them at each run.\n",
    "\n",
    "# Checking for txt file with list of systems\n",
    "p = Path('partition_list_teams_of5_DEMO.txt')\n",
    "if p.exists():\n",
    "   with open(p, \"r\") as f:\n",
    "       part_list = json.load(f)\n",
    "else:\n",
    "   print('creating partitions and saving to file')\n",
    "   part_list = list(partitions(player_names,5))\n",
    "   p.touch()\n",
    "   with open(p, \"w\") as f:\n",
    "       json.dump(part_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8607d1-81ab-413d-99e2-9fe81cd0a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_list = part_list[:3] # Let's just consider 3 different systems\n",
    "print('Total count of systems: ',len(part_list))\n",
    "start_time = time.time()\n",
    "\n",
    "print('Instantiate PD Experiments with different game types')\n",
    "classic_pdExp = pd_exp.PdExp(part_list)\n",
    "stag_pdExp = pd_exp.PdExp(part_list,game_type=stag)\n",
    "\n",
    "print('Running experiments and computing data')\n",
    "classic_pdExp.run_experiments()\n",
    "stag_pdExp.run_experiments()\n",
    "\n",
    "print('Save the data')\n",
    "path = 'Data/Experiment2/'\n",
    "classic_pdExp.save_data(path, 'ClassicPD_4x3_12uniq_DEMO')  # CHANGE file_name string when necessary\n",
    "stag_pdExp.save_data(path, 'StagHunt_4x3_12uniq_DEMO')  # CHANGE file_name string when necessary\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b23990-3610-496b-81ea-2817bde8768f",
   "metadata": {},
   "source": [
    "### Experiment 2: Data Comparison Across Systems, Teams, and Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261b6ab-0099-49d9-9d79-2478fd660d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the results\n",
    "# Retrieve the stored data\n",
    "classic_dataf = pd.read_csv('Data/Experiment2/ClassicPD_4x3_12uniq_DEMO_RPST_3_1_0_5.csv', index_col=0)\n",
    "stagHunt_dataf = pd.read_csv('Data/Experiment2/StagHunt_4x3_12uniq_DEMO_RPST_5_1_0_3.csv', index_col=0)\n",
    "\n",
    "# Reset the index to accurately count the total systems\n",
    "classic_dataf = classic_dataf.reset_index(drop=True)\n",
    "stagHunt_dataf = stagHunt_dataf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cd9e5-faf4-4ae2-9da1-1957a8c47ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The computed results create a large spreadsheet or dataframe. Here is a list of just the column names.\n",
    "classic_dataf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c026e256-0fa9-425b-a3a2-ed542b93949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(classic_dataf[['System ID', 'Team1', 'Team2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13136739-eb23-4119-944d-dee3e0f49e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(stagHunt_dataf[['System ID', 'Team1', 'Team2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b533adcd-2da0-4565-ae0f-a16f45e4c2cf",
   "metadata": {},
   "source": [
    "#### How do the systems compare within the same game?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e332e1-c7e1-46f1-b75c-d11e005fd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classic_dataf.loc[:,:'SYS CC Dist MIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537629d-cd63-405d-ab55-dc5897ea57b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stagHunt_dataf.loc[:,:'SYS CC Dist MIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0555f046-de39-4fe5-be41-0d3dd4375b2b",
   "metadata": {},
   "source": [
    "#### How did team 1 and 2 performance differ across systems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bcb8a-904c-4543-ba7f-2c5e1dae8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):  # more options can be specified also\n",
    "    display(classic_dataf[['System ID', 'Team1', 'Team1 Avg Score',\n",
    "       'Team1 Min Score', 'Team1 Avg CC Dist', 'Team2','Team2 Avg Score',\n",
    "       'Team2 Min Score', 'Team2 Avg CC Dist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb96808-64a9-4dcf-8088-885bac9d4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None, \n",
    "                       'display.max_colwidth', None):  # more options can be \n",
    "                                                       # specified also\n",
    "    display(stagHunt_dataf[['System ID', 'Team1', 'Team1 Avg Score',\n",
    "                            'Team1 Min Score', 'Team1 Avg CC Dist', 'Team2',\n",
    "                            'Team2 Avg Score', 'Team2 Min Score', \n",
    "                            'Team2 Avg CC Dist']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c640c-32d7-43f0-bb42-bc920a5a9045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
